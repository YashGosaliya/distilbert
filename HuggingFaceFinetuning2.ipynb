{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IfTBVEehsAmb"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def extract_zip(zip_path, extract_to='.'):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "zip_path = '/content/PDF Files.zip'\n",
        "extract_to = '/content/extracted_files'\n",
        "extract_zip(zip_path, extract_to)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoFfAEmjtzky",
        "outputId": "265bf53b-f3cd-4b93-fe89-77bb1729db1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import os\n",
        "\n",
        "def read_file(file_path):\n",
        "    text = ''\n",
        "    if file_path.endswith('.pdf'):\n",
        "        # Process PDF files\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in range(len(reader.pages)):\n",
        "                text += reader.pages[page].extract_text()\n",
        "    elif file_path.endswith('.txt'):\n",
        "        # Process text files\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    return text\n",
        "\n",
        "def load_text_from_extracted_files(extracted_to):\n",
        "    all_texts = []\n",
        "    for root, dirs, files in os.walk(extracted_to):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            all_texts.append(read_file(file_path))  # Append each file's text as a separate entry\n",
        "    return all_texts\n",
        "\n",
        "# 3. Process the ZIP and load text\n",
        "zip_path = '/content/PDF Files.zip'\n",
        "extract_to = '/content/extracted_files'\n",
        "extract_zip(zip_path, extract_to)\n",
        "all_texts = load_text_from_extracted_files(extract_to)\n",
        "\n",
        "# Read all files from extracted directory\n",
        "extracted_to = '/content/extracted_files'\n",
        "all_text = ''\n",
        "for root, dirs, files in os.walk(extracted_to):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "        all_text += read_file(file_path)"
      ],
      "metadata": {
        "id": "C4tg5S5Vtjti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "T0X94v84uoHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "# 5. Tokenize the dataset\n",
        "data = {'text': all_texts}\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "# 5. Tokenize the dataset\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
        "\n",
        "# Set the padding token to be the same as the end-of-sequence token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# 6. Set format for training\n",
        "tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask'])\n"
      ],
      "metadata": {
        "id": "5nk4avsuuesP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "\n",
        "# Define the model\n",
        "model = GPT2LMHeadModel.from_pretrained('distilgpt2')"
      ],
      "metadata": {
        "id": "gBwShpUDu0U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",  # Update to \"eval_strategy\" in future versions if needed\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=200,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Before training, print a sample from the dataset for verification\n",
        "print(tokenized_dataset[0])\n"
      ],
      "metadata": {
        "id": "-mskR1Ksu8zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./fine-tuned-distilgpt')\n",
        "tokenizer.save_pretrained('./fine-tuned-distilgpt')"
      ],
      "metadata": {
        "id": "_8nD8sQuvD04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the fine-tuned DistilGPT-2 model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('./fine-tuned-distilgpt')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('./fine-tuned-distilgpt')"
      ],
      "metadata": {
        "id": "J6o7tx_5vN8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What are the standards that talk about EMC?\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate text\n",
        "output = model.generate(input_ids, max_length=5000000, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "EelJWATJ3g81"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}